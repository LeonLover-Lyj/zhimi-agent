# ==========================================
#  çŸ¥è§… Agent â€“ Cursor é›¶äººå·¥æ„å»ºæŠ€æœ¯æ–‡æ¡£
#  æœ€ç»ˆä¿®æ­£ç‰ˆï¼šçœŸå®æ–‡æ¡£ + æ··åˆæ£€ç´¢ï¼ˆFAISS + BM25ï¼‰
# ==========================================

PROJECT_NAME:        "çŸ¥è§…-Agent"
REPO_DIR:            "zhimi-agent"
PYTHON_VERSION:      "3.10"
VENV_NAME:           "zhimi-agent"
MIN_GPU_MEM_GB:      0
TARGET_OS:           "linux / mac / win / wsl"

# ============= å…¨å±€è§„åˆ™ï¼ˆCursor å¼ºçº¦æŸï¼‰ =====================
RULES:
  - æ‰€æœ‰ Python å‘½ä»¤å¿…é¡»åœ¨ zhimi-agent è™šæ‹Ÿç¯å¢ƒä¸­æ‰§è¡Œ
  - ä¸å…è®¸ä½¿ç”¨ç³»ç»Ÿå…¨å±€ Python
  - ä¸ä¾èµ– poetry / conda
  - å¦‚å‘ç°ç¼ºå¤±æ–‡ä»¶ï¼Œå¿…é¡»è‡ªåŠ¨è¡¥é½
  - å¦‚æœ¬åœ°çŸ¥è¯†åº“æœªæ„å»ºï¼Œå·¥å…·å¿…é¡»è¿”å›å¯è§£é‡Šæç¤ºï¼Œè€Œä¸æ˜¯æŠ›å¼‚å¸¸
  - Agent ä¸å¾—åœ¨æ— å¿…è¦æ—¶è°ƒç”¨æœç´¢å·¥å…·

# ============= æ ¸å¿ƒèƒ½åŠ› =====================
REQUIREMENTS:
  - [x] å¤šè½®å¯¹è¯ï¼ˆæœ€è¿‘ 3 è½®ä¸Šä¸‹æ–‡ï¼‰
  - [x] æœ¬åœ°æ–‡æ¡£é—®ç­”ï¼ˆtxt / md / pdfï¼‰
  - [x] FAISS + BM25 æ··åˆæ£€ç´¢
  - [x] Agent è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦æœç´¢
  - [x] é˜²å¾¡å¼å¯åŠ¨ï¼ˆæ— ç´¢å¼•å¯è¿è¡Œï¼‰
  - [x] ä¸€é”®å¯åŠ¨ & éªŒæ”¶

# ============= æŠ€æœ¯é€‰å‹ =====================
LLM_PROVIDER:        "qwen"
LLM_MODEL:           "qwen-max"
EMBEDDING_MODEL:     "BAAI/bge-large-zh-v1.5"
VECTOR_DB:           "FAISS + BM25"
MEMORY_TYPE:         "ConversationBufferWindowMemory(k=3)"
AGENT_FRAMEWORK:     "LangChain 0.1.0"
WEB_UI:              "Streamlit 1.29"

# ============= ç›®å½•ç»“æ„ =====================
DIRECTORY_TREE: |
  zhimi-agent/
  â”œâ”€â”€ .cursorrules
  â”œâ”€â”€ .env.example
  â”œâ”€â”€ requirements.txt
  â”œâ”€â”€ scripts/
  â”‚   â””â”€â”€ index_local_docs.py
  â”œâ”€â”€ zhimi/
  â”‚   â”œâ”€â”€ agent.py
  â”‚   â”œâ”€â”€ llm.py
  â”‚   â”œâ”€â”€ tools/
  â”‚   â”‚   â””â”€â”€ search_tool.py
  â”‚   â”œâ”€â”€ prompts/
  â”‚   â”‚   â””â”€â”€ react_cn.txt
  â”‚   â””â”€â”€ ui/
  â”‚       â””â”€â”€ streamlit_app.py
  â”œâ”€â”€ data/
  â”‚   â””â”€â”€ sample/
  â”‚       â””â”€â”€ zhimi_readme.txt
  â”œâ”€â”€ memory/
  â”‚   â””â”€â”€ faiss_index/
  â”œâ”€â”€ zhimi-agent/        # Python venv
  â”œâ”€â”€ run.sh
  â””â”€â”€ run.bat

# ============= Step æ¸…å• ====================

STEP_001:
  name: "åˆ›å»ºç›®å½•ç»“æ„"
  cmd: |
    mkdir -p zhimi/{tools,prompts,ui} \
             scripts \
             data/sample \
             memory/faiss_index

STEP_002:
  name: "å†™å…¥ requirements.txt"
  file: "requirements.txt"
  content: |
    langchain==0.1.0
    langchain-openai==0.1.0
    faiss-cpu==1.7.4
    streamlit==1.29.0
    python-dotenv==1.0.1
    sentence-transformers==2.2.2
    unstructured==0.12.0
    pdfplumber==0.10.3
    rank-bm25==0.2.2

STEP_003:
  name: "åœ¨ zhimi-agent è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…ä¾èµ–"
  cmd: |
    set -e

    echo "ğŸ“¦ å‡è®¾å½“å‰å·²å¤„äº zhimi-agent è™šæ‹Ÿç¯å¢ƒ"
    python --version
    pip --version

    pip install --upgrade pip
    pip install -r requirements.txt

    echo "âœ… ä¾èµ–å®‰è£…å®Œæˆ"


STEP_004:
  name: "å†™å…¥ .env.example"
  file: ".env.example"
  content: |
    DASHSCOPE_API_KEY=your_dashscope_api_key
    LLM_MODEL=qwen-max

STEP_005:
  name: "å†™å…¥ç¤ºä¾‹æ–‡æ¡£"
  cmd: |
    echo "çŸ¥è§…ï¼ˆZhimiï¼‰æ˜¯ä¸€ä¸ªåŸºäºé€šä¹‰åƒé—®çš„æœ¬åœ°çŸ¥è¯†é—®ç­” Agentã€‚" > data/sample/zhimi_readme.txt

STEP_006:
  name: "æ„å»ºæœ¬åœ°çŸ¥è¯†åº“ç´¢å¼•è„šæœ¬"
  file: "scripts/index_local_docs.py"
  content: |
    import argparse
    from pathlib import Path
    from langchain.document_loaders import TextLoader, PyPDFLoader, UnstructuredMarkdownLoader
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain.embeddings import HuggingFaceBgeEmbeddings
    from langchain.vectorstores import FAISS

    INDEX_PATH = "memory/faiss_index"
    EMBED_MODEL = "BAAI/bge-large-zh-v1.5"

    def load_docs(data_dir: Path):
        docs = []
        for p in data_dir.rglob("*"):
            if p.suffix == ".txt":
                docs += TextLoader(str(p), encoding="utf-8").load()
            elif p.suffix == ".pdf":
                docs += PyPDFLoader(str(p)).load()
            elif p.suffix in [".md", ".markdown"]:
                docs += UnstructuredMarkdownLoader(str(p)).load()
        return docs

    def main(data_dir: str):
        raw_docs = load_docs(Path(data_dir))
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=100,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ"]
        )
        docs = splitter.split_documents(raw_docs)

        embeddings = HuggingFaceBgeEmbeddings(
            model_name=EMBED_MODEL,
            encode_kwargs={"normalize_embeddings": True}
        )

        vs = FAISS.from_documents(docs, embeddings)
        vs.save_local(INDEX_PATH)
        print(f"âœ… æ„å»ºå®Œæˆï¼Œæ–‡æ¡£ç‰‡æ®µæ•°ï¼š{len(docs)}")

    if __name__ == "__main__":
        parser = argparse.ArgumentParser()
        parser.add_argument("--dir", required=True)
        args = parser.parse_args()
        main(args.dir)

STEP_007:
  name: "ç”Ÿæˆæ··åˆæ£€ç´¢å·¥å…·ï¼ˆé˜²å¾¡å¼ï¼‰"
  file: "zhimi/tools/search_tool.py"
  content: |
    from pathlib import Path
    from langchain.tools import Tool
    from langchain.vectorstores import FAISS
    from langchain.embeddings import HuggingFaceBgeEmbeddings
    from langchain.retrievers import BM25Retriever
    from pydantic import BaseModel, Field

    INDEX_PATH = "memory/faiss_index"
    EMBED_MODEL = "BAAI/bge-large-zh-v1.5"

    embeddings = HuggingFaceBgeEmbeddings(
        model_name=EMBED_MODEL,
        encode_kwargs={"normalize_embeddings": True}
    )

    def load_retrievers():
        if not Path(INDEX_PATH).exists():
            return None, None
        faiss = FAISS.load_local(
            INDEX_PATH,
            embeddings,
            allow_dangerous_deserialization=True
        )
        bm25 = BM25Retriever.from_documents(list(faiss.docstore._dict.values()))
        bm25.k = 2
        return faiss, bm25

    faiss, bm25 = load_retrievers()

    def hybrid_search(query: str) -> str:
        if faiss is None or bm25 is None:
            return "âš ï¸ æœ¬åœ°çŸ¥è¯†åº“å°šæœªæ„å»ºï¼Œè¯·å…ˆæ„å»ºç´¢å¼•ã€‚"
        docs = faiss.similarity_search(query, k=2) + bm25.get_relevant_documents(query)
        uniq = {d.page_content: d for d in docs}
        return "\n".join(uniq.keys()) or "æœªæ‰¾åˆ°ç›¸å…³æœ¬åœ°ä¿¡æ¯ã€‚"

    class SearchInput(BaseModel):
        query: str = Field(description="ç”¨æˆ·é—®é¢˜")

    def build_search_tool():
        return Tool.from_function(
            func=hybrid_search,
            name="search_local_knowledge",
            description="ä»…å½“é—®é¢˜æ¶‰åŠæœ¬åœ°æ–‡æ¡£æˆ–é¡¹ç›®ç»†èŠ‚æ—¶ä½¿ç”¨",
            args_schema=SearchInput,
        )

STEP_008:
  name: "ç”Ÿæˆä¸­æ–‡ ReAct Prompt"
  file: "zhimi/prompts/react_cn.txt"
  content: |
    ä½ æ˜¯ã€ŒçŸ¥è§…ã€ï¼Œä¸€ä¸ªå¯ä»¥ä½¿ç”¨å·¥å…·çš„ä¸­æ–‡æ™ºèƒ½åŠ©æ‰‹ã€‚
    å¦‚æœé—®é¢˜æ˜¯å¸¸è¯†æ€§æˆ–é—²èŠé—®é¢˜ï¼Œä¸è¦è°ƒç”¨ä»»ä½•å·¥å…·ã€‚
    ä»…å½“é—®é¢˜æ¶‰åŠæœ¬åœ°æ–‡æ¡£ã€é¡¹ç›®è¯´æ˜ã€å®ç°ç»†èŠ‚æ—¶æ‰è°ƒç”¨å·¥å…·ã€‚

    å¯ç”¨å·¥å…·ï¼š
    {{tools}}

    ä½¿ç”¨æ ¼å¼ï¼š
    é—®é¢˜:
    æ€è€ƒ:
    è¡ŒåŠ¨:
    è¡ŒåŠ¨è¾“å…¥:
    è§‚å¯Ÿ:
    æœ€ç»ˆç­”æ¡ˆ:

    å½“å‰å¯¹è¯å†å²ï¼š
    {{chat_history}}

    é—®é¢˜: {{input}}
    æ€è€ƒ:

STEP_009:
  name: "ç”Ÿæˆ LLM å°è£…"
  file: "zhimi/llm.py"
  content: |
    import os
    from dotenv import load_dotenv
    from langchain_openai import ChatOpenAI

    load_dotenv()

    def get_llm():
        return ChatOpenAI(
            model=os.getenv("LLM_MODEL", "qwen-max"),
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            temperature=0.2,
        )

STEP_010:
  name: "ç”Ÿæˆ Agent"
  file: "zhimi/agent.py"
  content: |
    from langchain.agents import create_react_agent, AgentExecutor
    from langchain.memory import ConversationBufferWindowMemory
    from langchain.prompts import PromptTemplate
    from zhimi.llm import get_llm
    from zhimi.tools.search_tool import build_search_tool

    def load_agent():
        llm = get_llm()
        tools = [build_search_tool()]
        memory = ConversationBufferWindowMemory(
            k=3,
            memory_key="chat_history",
            return_messages=True
        )

        with open("zhimi/prompts/react_cn.txt", encoding="utf-8") as f:
            prompt = PromptTemplate.from_template(f.read())

        agent = create_react_agent(llm, tools, prompt)
        return AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)

STEP_011:
  name: "ç”Ÿæˆ Streamlit UI"
  file: "zhimi/ui/streamlit_app.py"
  content: |
    import streamlit as st
    from zhimi.agent import load_agent

    st.set_page_config(page_title="çŸ¥è§… Agent")
    st.title("ğŸŒ¿ çŸ¥è§… â€“ æœ¬åœ°çŸ¥è¯†é—®ç­”")

    agent = load_agent()

    if prompt := st.chat_input("è¯·è¾“å…¥é—®é¢˜"):
        with st.spinner("æ€è€ƒä¸­..."):
            res = agent.invoke({"input": prompt})
            st.chat_message("assistant").write(res["output"])

STEP_012:
  name: "å¯åŠ¨è„šæœ¬ run.sh"
  file: "run.sh"
  mode: "0755"
  content: |
    #!/usr/bin/env bash
    set -e
    VENV_NAME=zhimi-agent

    if [ ! -d "$VENV_NAME" ]; then
      echo "âŒ æœªæ‰¾åˆ°è™šæ‹Ÿç¯å¢ƒï¼Œè¯·å…ˆæ‰§è¡Œ STEP_003"
      exit 1
    fi

    source $VENV_NAME/bin/activate

    if [ ! -d memory/faiss_index ]; then
      python scripts/index_local_docs.py --dir data
    fi

    streamlit run zhimi/ui/streamlit_app.py

# ============= éªŒæ”¶ =========================
VERIFY_SCRIPT: |
  source zhimi-agent/bin/activate
  python - << 'EOF'
  from zhimi.agent import load_agent
  agent = load_agent()
  res = agent.invoke({"input": "çŸ¥è§…æ˜¯ä»€ä¹ˆï¼Ÿ"})
  assert "çŸ¥è§…" in res["output"]
  print("âœ… éªŒæ”¶é€šè¿‡")
  EOF
